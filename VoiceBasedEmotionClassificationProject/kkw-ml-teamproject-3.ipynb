{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-03T14:31:03.922037Z","iopub.execute_input":"2021-06-03T14:31:03.922406Z","iopub.status.idle":"2021-06-03T14:31:04.042535Z","shell.execute_reply.started":"2021-06-03T14:31:03.922374Z","shell.execute_reply":"2021-06-03T14:31:04.041284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport os\nfrom os.path import join","metadata":{"execution":{"iopub.status.busy":"2021-06-03T14:31:04.046295Z","iopub.execute_input":"2021-06-03T14:31:04.046621Z","iopub.status.idle":"2021-06-03T14:31:04.051934Z","shell.execute_reply.started":"2021-06-03T14:31:04.046586Z","shell.execute_reply":"2021-06-03T14:31:04.050842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DATA Load\n\nDATA_PATH = join('/kaggle','input','2021-ml-tp-p6')\npd_train = pd.read_csv(join(DATA_PATH, 'train_data.csv'))\npd_test = pd.read_csv(join(DATA_PATH, 'test_data.csv'))\n\nprint(pd_train.info(), pd_test.info())","metadata":{"execution":{"iopub.status.busy":"2021-06-03T14:31:04.054624Z","iopub.execute_input":"2021-06-03T14:31:04.05496Z","iopub.status.idle":"2021-06-03T14:31:04.101838Z","shell.execute_reply.started":"2021-06-03T14:31:04.054932Z","shell.execute_reply":"2021-06-03T14:31:04.100867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feature extraction**\n\n 1. Sampling&Quantization(continuos audio signal) --> Discrete audio signal\n 2. Short Time Fourier Transfrom(Discrete audio signal) --> Spectrogram\n 3. Mel-Filter(Spectrogram) --> Mel-Spectrogram\n 4. Discrete Cosine Transform(Mel-Spectrogram) --> Mel Frequency Cepstrum Coefficient\n \nAll of the above processes are implemented through functions provided by the librosa library. The following functions are used:\n1. librosa.load : Reading continuous audio signal (.wav file) as discrete audio signal.\n2. librosa.stft : FFT (Fast Fourier Transform) is performed after dividing the discrete audio signal by frame by windowing  \n[stft_documentation](https://librosa.org/doc/latest/generated/librosa.stft.html?highlight=stft)\n3. librosa.feature.melspectrogram : Mel-Spectrogram is created by applying Mel-filter to the spectrogram obtained through the stft function   as input.  \n[melspectrogram_documentation](https://librosa.org/doc/latest/generated/librosa.feature.melspectrogram.html?highlight=melspectrogram)\n4. librosa.feature.mfcc : MFCC is generated by performing DCT with the Mel-spectrogram obtained through the melspectrogram function as input.  [mfcc_documentation](https://librosa.org/doc/latest/generated/librosa.feature.mfcc.html?highlight=mfcc)","metadata":{}},{"cell_type":"code","source":"import librosa\nimport glob, pickle\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport librosa, librosa.display \n\n\ndef extract_feature(file_name):\n    # Function to extract speech features\n    # Input: name of .wav audio file\n    # Output: features processed from the input file (Spectrogram, Mel-spectrogram, MFCC)\n    \n    result=np.array([])\n    X, sample_rate = librosa.load(file_name, sr=22050)\n    \n    #----------step3. Finding the spectrogram---------------------\n    # 1. Using the input signal (X) as the input of the librosa.stft function, obtain the spectrogram.\n    # - Human voice cannot change the current spoken pronunciation within the time between 20 and 40 (ms).\n    # Therefore, when dividing the section on the time axis, adjust the n_fft parameter value in order to divide it within an interval of 20 to 40 (ms).\n    #\n    # 2. Take the absolute value of the spectrogram and convert it to a value in the form of a complex number.\n    #\n    # 3. To use the obtained spectrogram for training, take the average value of the frame axis and store it in spectrogram_feature.\n    # - Since the shape of the spectrogram is (length of frequency, number of frames)\n    # (Using the np.mean function, the shape of the spectrogram should be (1, length of frequency).)\n    # -----------------------------------------------------------------------------\n    \n    spectrogram = librosa.stft(X, n_fft = 462)\n    # Use the input signal X as input to the librosa.stft() function and adjust the n_fft parameter value to return a spectrogram.\n    \n    # Setting history for highest performance\n    # 92ms: n_fft = 2048, 23ms: n_fft = 512\n    # 20ms: 445.2 => 446 => 467 => 445 => 512 => 660 => 480 => 462\n\n    spectrogram = np.abs(spectrogram)\n    # It takes the absolute value of the spectrogram through the np.abs() function and converts it into a complex number.\n    spectrogram_feature = np.mean(spectrogram, axis = 1)\n    # Using the np.mean function, take the average value on the frame axis axis = 1 and store it in spectrogram_feature.\n    \n    #----------step4. Finding the Mel-spectrogram.--------------------\n    # 1. Create a power spectrogram by squaring the spectrogram obtained in step3-2.\n    #\n    # 2. Use the power spectrogram as input to the librosa.feature.melspectrogram function to obtain the mel-spectrogram.\n    #\n    # 3. Since the mel-spectrogram obtained in the previous process is a power-magnitude value,\n    # Convert power magnitude to decibel (db) value through librosa.power_to_db function.\n    #\n    # 4. To use the obtained mel-spectrogram for learning, take the average value of the frame axis and store it in mel_spectrogram_feature.\n    # - Since the shape of the mel-spectrogram is (length of frequency, number of frames)\n    # (Using the np.mean function, the shape of the spectrogram should be (1, length of frequency).)\n    # ------------------------------------------------- ----------------------------\n    \n    power_spectrogram = np.square(spectrogram)\n    mel_spectrogram = librosa.feature.melspectrogram(S = power_spectrogram) #446 => 467 => 512 => delete\n    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram)\n    mel_spectrogram_feature = np.mean(mel_spectrogram_db, axis = 1)\n\n     #----------step5. Finding the MFCC----------\n     # 1. Obtain MFCC by inputting the mel-spectrogram converted to decibel in step4-3 as input to the librosa.feature.mfcc function.\n     #\n     # 2. To use the obtained MFCC learning, take the average value of the frame axis and store it in mfcc_feature.\n     # - MFCC shape consists of (MFCC length, number of frames).\n     # (Using the np.mean function, the shape of the MFCC should be (1, the length of the MFCC))\n     # ------------------------------------------------- ----------------------------\n    \n    MFCC = librosa.feature.mfcc(S = mel_spectrogram_db)\n    mfcc_feature = np.mean(MFCC, axis = 1)\n\n    return spectrogram_feature, mel_spectrogram_feature, mfcc_feature ","metadata":{"execution":{"iopub.status.busy":"2021-06-03T14:31:04.10389Z","iopub.execute_input":"2021-06-03T14:31:04.104328Z","iopub.status.idle":"2021-06-03T14:31:04.117124Z","shell.execute_reply.started":"2021-06-03T14:31:04.104282Z","shell.execute_reply":"2021-06-03T14:31:04.116058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading Data**","metadata":{}},{"cell_type":"code","source":"#Load the data and extract features for each sound file\nfrom tqdm import tqdm\ndef load_data(data_info, isTrain=True):\n    \n    PATH = join('/kaggle','input','2021-ml-tp-p6')\n    if isTrain: #train_data\n        train_data = {'spectrogram':[],'mel':[],'mfcc':[]} #Dictionary of voice features\n        train_label = [] #List containing labels to be used for training\n        \n        file_list = data_info['file_name']\n        emotion_list = data_info['emotion']\n        for file_name, emotion in tqdm(zip(file_list, emotion_list)):\n            # Load the training data through the voice file name and emotion information in the train.csv file.\n            # Append the voice features obtained through extract_feature to the appropriate array in the train_data dictionary.\n\n            PATH_train = join(DATA_PATH, 'train_data', 'train_data', file_name)\n            spectrogram_feature, mel_spectrogram_feature, mfcc_feature = extract_feature(PATH_train)\n            train_data['spectrogram'].append(spectrogram_feature)\n            train_data['mel'].append(mel_spectrogram_feature)\n            train_data['mfcc'].append(mfcc_feature)\n            train_label.append(emotion)\n            \n        return train_data, np.array(train_label)\n    \n    else: #test_data\n        test_data = {'spectrogram':[],'mel':[],'mfcc':[]} #Dictionary of voice features\n        file_list = data_info['file_name']\n    \n        for file_name in tqdm(file_list):\n            PATH_test = join(DATA_PATH, 'test_data', 'test_data', file_name)\n\n            spectrogram_feature, mel_spectrogram_feature, mfcc_feature = extract_feature(PATH_test)\n            test_data['spectrogram'].append(spectrogram_feature)\n            test_data['mel'].append(mel_spectrogram_feature)\n            test_data['mfcc'].append(mfcc_feature)\n            \n        return test_data\n\n#Split the dataset\ntrain_data, y_train = load_data(pd_train)\ntest_data = load_data(pd_test, isTrain=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T14:31:04.180456Z","iopub.execute_input":"2021-06-03T14:31:04.180821Z","iopub.status.idle":"2021-06-03T14:35:02.238605Z","shell.execute_reply.started":"2021-06-03T14:31:04.180776Z","shell.execute_reply":"2021-06-03T14:35:02.237228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training and inference\n1. Obtained **spectrogram** through Short Time Fourier Transform (stft) for voice signal,\n2. By applying mel-filter to the obtained spectrogram, **mel-spectrogram** was obtained.\n3. Finally, **mfcc** was calculated by taking discrete cosine transform (DCT) on the mel-spectrogram.\n\nAll of the features obtained above are features that can be used for model learning in various tasks using voice data (human voice classification, emotion classification through voice, etc.).\nCheck how much the accuracy of the model according to each **feature is different**.\n\n- The classifier uses sklearn's **RandomForestClassifier**.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nsample = pd.read_csv(join(DATA_PATH,'sample_submit.csv'))\n\n\nfor feature_name in train_data.keys():\n    # Spectrogram, mel-spectrogram, and mfcc features exist in the train_data variable in dictionary form.\n    x_train = np.array(train_data[feature_name])\n    x_test = np.array(test_data[feature_name])\n    \n    rlf = RandomForestClassifier(criterion = 'entropy', random_state = 1) # setting parameters\n    rlf.fit(x_train, y_train) # training model\n    predict = rlf.predict(x_test) # predict\n    \n    # class_weight => default (Points drop when used)\n    # min_samples_split => default (Points drop when used)\n    # min_samples_leaf => default (Points drop when used)\n    \n    # baseline 1 (spectrogram) : 0.46064\n    # n_fft = 445, criterion = 'entropy', random_state = 1 // kaggle: 0.46527\n    # n_fft = 512, criterion = 'entropy', random_state = 1 // kaggle : 0.48148\n    \n    # baseline 2 (mel-spectrogram) : 0.47222\n    # n_fft = 445, criterion = 'entropy', random_state = 1 // kaggle: 0.46990\n    # n_fft = 445, criterion = 'entropy', max_depth = 800, random_state = 1 // kaggle: 0.46990\n    # n_fft = 445, criterion = 'gini', random_state = 1 // kaggle: 0.44907\n    # n_fft = 512, criterion = 'entropy', random_state = 1 // kaggle: 0.49305 **\n    # n_fft = 660, criterion = 'entropy', random_state = 1 // kaggle: 0.47453\n    # n_fft = 480, criterion = 'entropy', random_state = 1 // kaggle: 0.48148\n    # n_fft = 462, criterion = 'entropy', random_state = 1 // kaggle: 0.47453\n    \n    # baseline 3 (RF_baseline) : 0.51620\n    # n_fft = 445, criterion = 'entropy', random_state = 1 // kaggle: 0.56250\n    # n_fft = 445, criterion = 'entropy', max_depth = 800, random_state = 1 // kaggle: 56250\n    # n_fft = 512, criterion = 'entropy', random_state = 1 // kaggle : 0.56944\n    # n_fft = 660, criterion = 'entropy', random_state = 1 // kaggle: 0.55787\n    # n_fft = 480, criterion = 'entropy', random_state = 1 // kaggle: 0.57407 **\n    # n_fft = 462, criterion = 'entropy', random_state = 1 // kaggle: 0.57175\n\n\n    sample['emotion'] = predict.reshape(-1,1)\n    sample.to_csv(join(feature_name+'.csv'),index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T14:35:02.240988Z","iopub.execute_input":"2021-06-03T14:35:02.241405Z","iopub.status.idle":"2021-06-03T14:35:09.111333Z","shell.execute_reply.started":"2021-06-03T14:35:02.24136Z","shell.execute_reply":"2021-06-03T14:35:09.110427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}